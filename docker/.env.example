# Ollama configuration for local development
OLLAMA_IP=localhost
OLLAMA_PORT=11434
OLLAMA_MODEL=llama3.2

#OpenAI configuration for local development
OPENAI_MODEL=gpt-4.1-nano
OPENAI_API_KEY=your_openai_api_key_here

# LLM Provider configuration - specify which provider to use
LLM_PROVIDER=ollama

# Hatch configuration
HATCH_HOST_CACHE_DIR=./.hatch # the directory where cache will be stored on the host machine
# Local packages directory
# Modify this path to point to the directory where your local packages are stored (if any).
# e.g. If you are have a package called "my_package" in "<path_to_my_package>/my_package",
# set it to <path_to_my_package>. By default it points to a folder "Hatch_Pkg_Dev" in the
# parent directory of "Hatchling"
HATCH_LOCAL_PACKAGE_DIR=../../Hatch_Pkg_Dev # the directory where packages will be stored on the host machine

# Hatchling configuration
# The directory where Hatchling source code is located.
HATCHLING_SOURCE_DIR=/opt/Hatchling

# The default language for Hatchling's UI
HATCHLING_DEFAULT_LANGUAGE=en

# Logging configuration
LOG_LEVEL=INFO

# Docker configuration
NETWORK_MODE=host

# User configuration (leave empty to use defaults from docker-compose)
# On Linux, set these to match your host user to avoid permission issues
USER_ID=1002
GROUP_ID=1002

# Set the user name if you want to use a specific user name inside the container.
# Defaults to 'HatchlingUser' if not set.
# If you are using a specific USER_ID and GROUP_ID, set USER_NAME to match your
# host user name for consistency. For example, if your host user name is "SuperMario"
# with USER_ID=1000 and GROUP_ID=1000, we recommend setting USER_NAME=SuperMario.
#
USER_NAME=HatchlingUser
